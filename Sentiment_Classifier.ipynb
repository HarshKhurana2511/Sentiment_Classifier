{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJVFQllkwzsQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import pad_sequences\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this dataset word encoding is like if a interger to a word is 3 it is referred as 3rd most common word in the data set.\n",
        "Hence, num_words=Vocab_Size refers to load 88584 unique words in dataset"
      ],
      "metadata": {
        "id": "0tIUYyPmyeo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 88584\n",
        "\n",
        "Max_Len = 250\n",
        "Batch_Size = 64\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu-TbBOnxfPq",
        "outputId": "96ad045f-da90-4043-bfaf-ff58dcc578a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(train_data[0])\n",
        "print(train_labels[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4ao8u2b1Tg-",
        "outputId": "351631fd-6151-4bd9-e35d-fb39afe4af42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data[0]))\n",
        "print(len(train_data[1]))\n",
        "print(len(train_data[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfNrzB6o1XdA",
        "outputId": "517eb87d-c1fb-4f3f-bab4-25e99db1e54b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "218\n",
            "189\n",
            "141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In order to make our all reviews of same size\n",
        "train_data = pad_sequences(train_data, Max_Len)\n",
        "test_data = pad_sequences(test_data, Max_Len)"
      ],
      "metadata": {
        "id": "5SyJGe_21ljV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data[0]))\n",
        "print(len(train_data[1]))\n",
        "print(len(train_data[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OcR0au32DEi",
        "outputId": "e6ec4163-774d-41a2-a8b8-033f64173c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250\n",
            "250\n",
            "250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "f8rqn__f2w4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQMejefP367L",
        "outputId": "dfbb9e0a-a5e4-4265-94e6-74e19f3a371a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          2834688   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                8320      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,843,041\n",
            "Trainable params: 2,843,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"binary_crossentropy\", optimizer = \"rmsprop\", metrics = ['acc'])"
      ],
      "metadata": {
        "id": "lPIJ7yQG3-CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data, train_labels, epochs = 10, validation_split = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeFlU5l742Rt",
        "outputId": "0337e20c-460e-4679-a944-57d906de2a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 68s 96ms/step - loss: 0.4503 - acc: 0.7859 - val_loss: 0.3114 - val_acc: 0.8696\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.2611 - acc: 0.9002 - val_loss: 0.2910 - val_acc: 0.8832\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.1997 - acc: 0.9277 - val_loss: 0.2794 - val_acc: 0.8868\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 0.1613 - acc: 0.9426 - val_loss: 0.3024 - val_acc: 0.8712\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.1362 - acc: 0.9543 - val_loss: 0.3134 - val_acc: 0.8768\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 9s 15ms/step - loss: 0.1119 - acc: 0.9631 - val_loss: 0.3884 - val_acc: 0.8832\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0966 - acc: 0.9694 - val_loss: 0.3481 - val_acc: 0.8820\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 9s 15ms/step - loss: 0.0835 - acc: 0.9735 - val_loss: 0.3672 - val_acc: 0.8806\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 9s 15ms/step - loss: 0.0678 - acc: 0.9791 - val_loss: 0.4299 - val_acc: 0.8738\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0576 - acc: 0.9827 - val_loss: 0.4750 - val_acc: 0.8738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNmE6b1w6a1t",
        "outputId": "75ee2272-2080-4148-a3e1-363850d5fefa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 5s 6ms/step - loss: 0.5318 - acc: 0.8580\n",
            "[0.5317881107330322, 0.8580399751663208]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.preprocessing\n",
        "\n",
        "word_index = imdb.get_word_index() #mapping from which our old data was encoded\n",
        "\n",
        "def encode_text(text):  #Covert Any text to proper preproccesed sentence according to loaded dataset\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return pad_sequences([tokens], Max_Len)[0]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k8baVTx99tD",
        "outputId": "74a26000-07c6-415f-ec26-6173467c8ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"that movie was just amazing, so amazing\"\n",
        "encoded = encode_text(text)\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLTpbKHjBoBe",
        "outputId": "c215881f-bd77-4298-fd9f-b6405f06c552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#decode function\n",
        "\n",
        "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
        "\n",
        "def decode_integers(integers):\n",
        "  PAD = 0\n",
        "  text = \"\"\n",
        "  for num in integers:\n",
        "    if num != PAD:\n",
        "      text += reverse_word_index[num] + \" \"\n",
        "  return text[:-1]"
      ],
      "metadata": {
        "id": "EvB61YCcBrTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode_integers(encoded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO_QrdsSFWp2",
        "outputId": "7348f8ba-c61a-4ff1-ac4e-b3203a836fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "that movie was just amazing so amazing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,250))\n",
        "  pred[0] = encoded_text\n",
        "  results = model.predict(pred)\n",
        "  print(results[0])"
      ],
      "metadata": {
        "id": "FvVRl29dFmPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter Review: \")\n",
        "result = np.argmax(predict(text)) #To convert into Int\n",
        "if result >= 0.5:\n",
        "  print(\"Positive Review\")\n",
        "else:\n",
        "  print(\"Negitive Review\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oUYdJmnGVoF",
        "outputId": "773d2449-87ed-4f02-ceea-61ae001043b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Review: It is so bad that i hate it\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "[0.14751723]\n",
            "Negitive Review\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YX3pc7ZxG7iC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}